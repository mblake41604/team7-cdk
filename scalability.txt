Scalability was an important aspect to our project. As a submission site, we’re continuously gathering and storing incoming data, but how does scalability work alongside with the other aws services we used? Acting as the frontend of our website, the API gateway receives HTTP requests in the form of application answers and routes each HTTP request to a corresponding lambda function. While this happens, the API gateway automatically scales to handle the traffic our API receives so that requests still run smoothly in cases of traffic spikes.
Moving along, each HTTP request invokes a separate instance of the lambda function, so AWS Lambda automatically scales to process multiple requests in parallel. Currently, our default concurrency limit of 1000 is more than enough to handle all our lambda functions given how small scale our project is.
	And finally, we have Amazon DynamoDB, which is a fully managed database who’s table can automatically scale up and down its capacity to meet the needs of the application. When job submissions are sent through the website, auto scaling uses CloudWatch alarms to quickly adapt to the new traffic, updating the table’s provisions to match the load.
